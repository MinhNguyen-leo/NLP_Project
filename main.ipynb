{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d752adbd",
   "metadata": {},
   "source": [
    "# Seq2Seq Translation with LSTM  \n",
    "### English to French Machine Translation\n",
    "\n",
    "### Authors:\n",
    "* Hu·ª≥nh Anh Nh·ª±t\n",
    "* Nguy·ªÖn Ti·∫øn Minh\n",
    "\n",
    "**Bao g·ªìm:**\n",
    "- Chu·∫©n b·ªã d·ªØ li·ªáu (raw ‚Üí processed)\n",
    "- Encoder‚ÄìDecoder LSTM\n",
    "- Training loop (teacher forcing)\n",
    "- Inference (translate function)\n",
    "- Evaluation (BLEU score)\n",
    "- 5 v√≠ d·ª• d·ªãch + ph√¢n t√≠ch l·ªói\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b517346",
   "metadata": {},
   "source": [
    "### Import th∆∞ vi·ªán "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4f66a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import random\n",
    "from processed_data import (en_tokenizer, fr_tokenizer,build_vocab, load_parallel, ParallelDataset, make_collate_fn, encode_sentence_en, encode_sentence_fr, save_vocab, load_vocab, save_dataset_pytorch, load_dataset_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deaa634",
   "metadata": {},
   "source": [
    "# 1. Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e2930a",
   "metadata": {},
   "source": [
    "### T·∫°o dataset m·ªõi t·ª´ raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ff97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pairs = load_parallel('./data/raw/train.en', './data/raw/train.fr')\n",
    "# val_pairs = load_parallel('./data/raw/val.en', './data/raw/val.fr')\n",
    "# test_pairs = load_parallel('./data/raw/test_2016_flickr.en', './data/raw/test_2016_flickr.fr')\n",
    "\n",
    "# vocab_en = build_vocab(train_pairs, lang='en', max_tokens=10000, min_freq=2)\n",
    "# vocab_fr = build_vocab(train_pairs, lang='fr', max_tokens=10000, min_freq=2)\n",
    "\n",
    "# save_vocab(vocab_en, './data/processed/vocab_en.pkl')\n",
    "# save_vocab(vocab_fr, './data/processed/vocab_fr.pkl')\n",
    "\n",
    "# train_ds = ParallelDataset(train_pairs, vocab_en, vocab_fr)\n",
    "# val_ds = ParallelDataset(val_pairs, vocab_en, vocab_fr)\n",
    "# test_ds = ParallelDataset(test_pairs, vocab_en, vocab_fr)\n",
    "\n",
    "# save_dataset_pytorch(train_ds, './data/processed/train_ds.pt')\n",
    "# save_dataset_pytorch(val_ds, './data/processed/val_ds.pt')\n",
    "# save_dataset_pytorch(test_ds, './data/processed/test_ds.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc9627",
   "metadata": {},
   "source": [
    "### Load dataset ƒë√£ qua x·ª≠ l√Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a5e066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_en = load_vocab('./data/processed/vocab_en.pkl')\n",
    "vocab_fr = load_vocab('./data/processed/vocab_fr.pkl')\n",
    "\n",
    "train_ds = load_dataset_pytorch('./data/processed/train_dataset.pt')\n",
    "valid_ds = load_dataset_pytorch('./data/processed/valid_dataset.pt')\n",
    "test_ds = load_dataset_pytorch('./data/processed/test_dataset.pt')\n",
    "\n",
    "collate_fn = make_collate_fn(vocab_en, vocab_fr)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c759fba6",
   "metadata": {},
   "source": [
    "# 2. LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091c1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.W_i = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.U_i = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.W_f = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.U_f = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.W_o = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.U_o = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.W_c = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.U_c = nn.Linear(hidden_size, hidden_size,  bias=True)\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        i_t = torch.sigmoid(self.W_i(x) + self.U_i(h_prev))\n",
    "        f_t = torch.sigmoid(self.W_f(x) + self.U_f(h_prev))\n",
    "        o_t = torch.sigmoid(self.W_o(x) + self.U_o(h_prev))\n",
    "        c_tilde_t = torch.tanh(self.W_c(x) + self.U_c(h_prev))\n",
    "        c_t = f_t * c_prev + i_t * c_tilde_t\n",
    "        h_t = o_t * torch.tanh(c_t)\n",
    "        return h_t, c_t\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cells = nn.ModuleList([LSTMCell(input_size if i == 0 else hidden_size, hidden_size) for i in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, h_0=None, c_0=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        if h_0 is None:\n",
    "            h_0 = [torch.zeros(batch_size, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n",
    "        if c_0 is None:\n",
    "            c_0 = [torch.zeros(batch_size, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n",
    "\n",
    "        h_n = []\n",
    "        c_n = []\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "            for layer in range(self.num_layers):\n",
    "                h_prev = h_0[layer]\n",
    "                c_prev = c_0[layer]\n",
    "                h_t, c_t = self.cells[layer](x_t, h_prev, c_prev)\n",
    "                h_0[layer] = h_t\n",
    "                c_0[layer] = c_t\n",
    "                x_t = h_t\n",
    "            outputs.append(h_t.unsqueeze(1))\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        h_n = h_0\n",
    "        c_n = c_0\n",
    "\n",
    "        return outputs, (h_n, c_n)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, num_layers=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        self.lstm = LSTM(embed_size, hidden_size, num_layers)\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (h_n, c_n) = self.lstm(embedded)\n",
    "        return outputs, (h_n, c_n)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, embed_size, hidden_size, num_layers=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, embed_size)\n",
    "        self.lstm = LSTM(embed_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x, h_0, c_0):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (h_n, c_n) = self.lstm(embedded, h_0, c_0)\n",
    "        logits = self.fc(outputs)\n",
    "        return logits, (h_n, c_n)\n",
    "    \n",
    "    def forward_step(self, y_prev, h, c):\n",
    "        # y_prev: (batch,)\n",
    "        y_prev = y_prev.unsqueeze(1)         # (batch, 1)\n",
    "        embedded = self.embedding(y_prev)    # (batch, 1, embed)\n",
    "        \n",
    "        outputs, (h, c) = self.lstm(embedded, h, c)\n",
    "        logits = self.fc(outputs[:, -1, :])  # l·∫•y token cu·ªëi\n",
    "\n",
    "        return logits, h, c\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, sos_id, eos_id):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sos_id = sos_id\n",
    "        self.eos_id = eos_id\n",
    "    \n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size, tgt_len = tgt.size()\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, tgt_len, vocab_size, device=src.device)\n",
    "\n",
    "        # encoder produce h, c\n",
    "        encoder_outputs, (h, c) = self.encoder(src)\n",
    "\n",
    "        # start token\n",
    "        y_prev = torch.full((batch_size,), self.sos_id, device=src.device)\n",
    "\n",
    "        for t in range(tgt_len):\n",
    "            probs, h, c = self.decoder.forward_step(y_prev, h, c)\n",
    "            outputs[:, t, :] = probs\n",
    "\n",
    "            # teacher forcing\n",
    "            use_tf = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            y_prev = tgt[:, t] if use_tf else probs.argmax(dim=-1)\n",
    "\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3581813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # S·ª≠ d·ª•ng GPU ƒë·ªÉ train m√¥ h√¨nh LSTM\n",
    "\n",
    "encoder = Encoder(input_size=len(vocab_en), embed_size=256, hidden_size=512, num_layers=2)\n",
    "decoder = Decoder(output_size=len(vocab_fr), embed_size=256, hidden_size=512, num_layers=2)\n",
    "seq2seq_model = Seq2Seq(encoder, decoder, sos_id=vocab_fr['<sos>'], eos_id=vocab_fr['<eos>']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d163e",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "030d638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = vocab_fr.stoi['<pad>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizer = torch.optim.Adam(seq2seq_model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, patience=1, factor=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6c3be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, num_epochs=20, teacher_forcing_ratio=0.5):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for src, tgt, src_lens, tgt_lens in train_loader:\n",
    "            \n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(src, tgt, teacher_forcing_ratio)   # (B, T, V)\n",
    "            outputs = outputs[:, :-1, :].reshape(-1, outputs.size(-1))\n",
    "            tgt_gold = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, tgt_gold)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # ---- VALIDATION ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for src, tgt, _, _ in valid_loader:\n",
    "                \n",
    "                src = src.to(device)\n",
    "                tgt = tgt.to(device)\n",
    "\n",
    "                outputs = model(src, tgt, 0)\n",
    "                outputs = outputs[:, :-1, :].reshape(-1, outputs.size(-1))\n",
    "                tgt_gold = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "                loss = criterion(outputs, tgt_gold)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "            print(\"  ‚Üí Saved best model\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 3:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc005746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train: 2224.9224 | Val: 74.3829\n",
      "  ‚Üí Saved best model\n",
      "Epoch 2 | Train: 1874.9713 | Val: 66.5534\n",
      "  ‚Üí Saved best model\n",
      "Epoch 3 | Train: 1684.9115 | Val: 62.3529\n",
      "  ‚Üí Saved best model\n",
      "Epoch 4 | Train: 1541.7229 | Val: 59.6397\n",
      "  ‚Üí Saved best model\n",
      "Epoch 5 | Train: 1424.7440 | Val: 56.5635\n",
      "  ‚Üí Saved best model\n",
      "Epoch 6 | Train: 1317.3354 | Val: 54.7719\n",
      "  ‚Üí Saved best model\n",
      "Epoch 7 | Train: 1216.8709 | Val: 53.9466\n",
      "  ‚Üí Saved best model\n",
      "Epoch 8 | Train: 1124.5261 | Val: 52.9172\n",
      "  ‚Üí Saved best model\n",
      "Epoch 9 | Train: 1046.1415 | Val: 52.8430\n",
      "  ‚Üí Saved best model\n",
      "Epoch 10 | Train: 972.2116 | Val: 52.6479\n",
      "  ‚Üí Saved best model\n",
      "Epoch 11 | Train: 904.9045 | Val: 51.9730\n",
      "  ‚Üí Saved best model\n",
      "Epoch 12 | Train: 844.6209 | Val: 52.4782\n",
      "Epoch 13 | Train: 782.2043 | Val: 52.7849\n",
      "Epoch 14 | Train: 679.1109 | Val: 53.1211\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "train_model(seq2seq_model, train_loader, valid_loader, num_epochs=20, teacher_forcing_ratio=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77679feb",
   "metadata": {},
   "source": [
    "# 4. D·ªãch t·∫≠p test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c62dd6fa-4f6a-4bce-899a-849052339dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, model, vocab_en, vocab_fr, max_len=50):\n",
    "    model.eval()\n",
    "\n",
    "    # tokenize\n",
    "    tokens = list(en_tokenizer(sentence))\n",
    "    ids = [vocab_en.stoi.get(tok, vocab_en.stoi[\"<unk>\"]) for tok in tokens]\n",
    "    src = torch.tensor(ids).unsqueeze(0).to(next(model.parameters()).device)\n",
    "\n",
    "    # encode\n",
    "    _, (h, c) = model.encoder(src)\n",
    "\n",
    "    # decode t·ª´ng b∆∞·ªõc\n",
    "    y_prev = torch.tensor([vocab_fr.stoi[\"<sos>\"]], device=src.device)\n",
    "    result_ids = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        probs, h, c = model.decoder.forward_step(y_prev, h, c)\n",
    "        y_prev = probs.argmax(dim=-1)\n",
    "\n",
    "        token_id = y_prev.item()\n",
    "        if token_id == vocab_fr.stoi[\"<eos>\"]:\n",
    "            break\n",
    "        \n",
    "        result_ids.append(token_id)\n",
    "\n",
    "    # convert id -> word b·∫±ng vocab_fr.itos\n",
    "    words = [vocab_fr.itos[i] for i in result_ids]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24c073d7-240f-46a3-8925-7ab978c8ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tensor(tensor_ids, vocab):\n",
    "    # vocab.itos l√† list: index -> token\n",
    "    tokens = []\n",
    "    for idx in tensor_ids.tolist():\n",
    "        if idx < len(vocab.itos):\n",
    "            tokens.append(vocab.itos[idx])\n",
    "    # b·ªè pad/sos/eos\n",
    "    tokens = [t for t in tokens if t not in [\"<pad>\", \"<sos>\", \"<eos>\"]]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def show_examples(test_ds, model, vocab_en, vocab_fr, n=5):\n",
    "    for i in range(n):\n",
    "        src_tensor, tgt_tensor = test_ds[i]\n",
    "\n",
    "        eng = decode_tensor(src_tensor, vocab_en)\n",
    "        fr  = decode_tensor(tgt_tensor, vocab_fr)\n",
    "        pred = translate(eng, model, vocab_en, vocab_fr)\n",
    "\n",
    "        print(f\"\\n[Example {i+1}]\")\n",
    "        print(f\"EN:   {eng}\")\n",
    "        print(f\"FR:   {fr}\")\n",
    "        print(f\"PRED: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb09c44a-2ab1-4b88-8193-156dcb8e4e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Example 1]\n",
      "EN:   A man in an orange hat starring at something .\n",
      "FR:   Un homme avec un chapeau orange regardant quelque chose .\n",
      "PRED: Un homme avec un chapeau orange √† quelque chose\n",
      "\n",
      "[Example 2]\n",
      "EN:   A Boston Terrier is running on lush green grass in front of a white fence .\n",
      "FR:   Un terrier de Boston court sur l' herbe verdoyante devant une cl√¥ture blanche .\n",
      "PRED: Un nouveau - de est allong√© sur sur herbe verte sur une verte verte .\n",
      "\n",
      "[Example 3]\n",
      "EN:   A girl in karate uniform breaking a stick with a front kick .\n",
      "FR:   Une fille en tenue de karat√© brisant un b√¢ton avec un coup de pied .\n",
      "PRED: Une fille en tenue de bain un un un avec un un de de .\n",
      "\n",
      "[Example 4]\n",
      "EN:   Five people wearing winter jackets and helmets stand in the snow , with <unk> in the background .\n",
      "FR:   Cinq personnes avec des vestes d' hiver et des casques sont debout dans la neige , avec des <unk> en arri√®re-plan .\n",
      "PRED: Cinq personnes portant des casques de des et des des , sur la dans rue , avec des et et des en en .\n",
      "\n",
      "[Example 5]\n",
      "EN:   People are fixing the roof of a house .\n",
      "FR:   Des gens r√©parent le toit d' une maison .\n",
      "PRED: Des gens le sommet d' d' rampe .\n"
     ]
    }
   ],
   "source": [
    "seq2seq_model.load_state_dict(torch.load(\"best_model.pt\", map_location=device))\n",
    "seq2seq_model.eval()\n",
    "show_examples(test_ds, seq2seq_model, vocab_en, vocab_fr, n=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c108122",
   "metadata": {},
   "source": [
    "# 5. ƒê√°nh gi√° m√¥ h√¨nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c89d4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import torch\n",
    "\n",
    "def compute_bleu(model, test_ds, vocab_en, vocab_fr, max_samples=500):\n",
    "    model.eval()\n",
    "    smoothie = SmoothingFunction().method1\n",
    "\n",
    "    inv_fr = {i: tok for tok, i in vocab_fr.stoi.items()}\n",
    "\n",
    "    def tensor_to_sentence(tensor_ids):\n",
    "        words = []\n",
    "        for idx in tensor_ids:\n",
    "            token = inv_fr.get(idx.item(), \"<unk>\")\n",
    "            if token in [\"<sos>\", \"<pad>\"]:\n",
    "                continue\n",
    "            if token == \"<eos>\":\n",
    "                break\n",
    "            words.append(token)\n",
    "        return words\n",
    "\n",
    "    total_bleu = 0\n",
    "    count = min(max_samples, len(test_ds))\n",
    "\n",
    "    for i in range(count):\n",
    "        src_tensor, tgt_tensor = test_ds[i]\n",
    "\n",
    "        # convert tgt_tensor ‚Üí list token words\n",
    "        tgt_tokens = tensor_to_sentence(tgt_tensor)\n",
    "\n",
    "        # translate predicted\n",
    "        inv_en = {i: tok for tok, i in vocab_en.stoi.items()}\n",
    "\n",
    "        src_words = []\n",
    "        for tok in src_tensor:\n",
    "            word = inv_en.get(tok.item(), \"<unk>\")\n",
    "            if word in [\"<pad>\", \"<sos>\", \"<eos>\"]:\n",
    "                continue\n",
    "            src_words.append(word)\n",
    "\n",
    "        src_sentence = \" \".join(src_words)\n",
    "\n",
    "        pred_text = translate(src_sentence, model, vocab_en, vocab_fr)\n",
    "\n",
    "        pred_tokens = pred_text.split()\n",
    "\n",
    "        # compute BLEU (unigram + bigram)\n",
    "        bleu = sentence_bleu(\n",
    "            [tgt_tokens], pred_tokens,\n",
    "            smoothing_function=smoothie,\n",
    "            weights=(0.5, 0.5, 0, 0)\n",
    "        )\n",
    "        total_bleu += bleu\n",
    "\n",
    "    bleu_score = total_bleu / count\n",
    "    print(f\"\\nüîµ BLEU score = {bleu_score:.4f} on {count} samples\")\n",
    "    return bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cead02e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîµ BLEU score = 0.3610 on 500 samples\n"
     ]
    }
   ],
   "source": [
    "bleu = compute_bleu(seq2seq_model, test_ds, vocab_en, vocab_fr, max_samples=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2d5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
